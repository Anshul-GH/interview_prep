{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. Introduction - Self\r\n",
    "2. Check for candidate's name\r\n",
    "3. Explain the interview flow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Basic/Intermediate\r\n",
    "\r\n",
    "# B1. Given a list:\r\n",
    "[1,2,3,4,6,7,8,9,12,4,2,5,7,2,5,2,1,4,6,3]\r\n",
    "# Push all the even numbers to the front and odd numbers to the back\r\n",
    "# Expected Output:\r\n",
    "[2,4,6,8,12,4,2,2,2,4,6,1,3,7,9,5,7,5,1,3]\r\n",
    "# Do not use any temporary variables."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# M2. Given two integer arrays nums1 and nums2, return an array of their intersection. \r\n",
    "# Each element in the result must appear as many times as it shows in both arrays and you may return the result in any order.\r\n",
    "# Example 1:\r\n",
    "# Input: \r\n",
    "nums1 = [1,2,2,1], nums2 = [2,2]\r\n",
    "# Output: \r\n",
    "[2,2]\r\n",
    "# Example 2:\r\n",
    "# Input: \r\n",
    "nums1 = [4,9,5], nums2 = [9,4,9,8,4]\r\n",
    "# Output: \r\n",
    "[4,9]\r\n",
    "# Explanation: [9,4] is also accepted."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. End-to-end Machine Learning lifecycle\r\n",
    "Here are the steps involved in an ML model lifecycle.\r\n",
    "\r\n",
    "Step 1: Business context and define a problem\r\n",
    "\r\n",
    "Step 2: Translating to AI problem and approach\r\n",
    "\r\n",
    "Step 3: Milestones and Planning\r\n",
    "\r\n",
    "Step 4: Data gathering and Understanding\r\n",
    "\r\n",
    "Step 5: Data preparation\r\n",
    "\r\n",
    "Step 6: Data Cleaning\r\n",
    "\r\n",
    "Step 7: Exploratory data analysis\r\n",
    "\r\n",
    "Step 8: Feature engineering and selection\r\n",
    "\r\n",
    "Step 9: ML Model assumption and checks\r\n",
    "\r\n",
    "Step 10: Data preparation for modelling\r\n",
    "\r\n",
    "Step 11: Model Building\r\n",
    "\r\n",
    "Step 12: Model Validation & Evaluation\r\n",
    "\r\n",
    "Step 13: Predictions & Model deployment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. What is the Differentiate between Univariate, Bivariate, and Multivariate analysis?\r\n",
    "1. Univariate:\r\n",
    "    When we analyze one variable at a time, it is called univariate data analysis. \r\n",
    "    This analysis aims to describe the variable in question and find patterns that exist within it. \r\n",
    "    Example: height of students\r\n",
    "2. Bivariate:\r\n",
    "    Bivariate data involves two different variables. \r\n",
    "    The analysis of this type of data deals with causes and relationships. \r\n",
    "    The investigation determines the relationship between the two variables, where one of the variables is the target variable. \r\n",
    "    Example: temperature and ice cream sales in the summer season.\r\n",
    "3. Multivariate: \r\n",
    "    Analyzing three or more variables together is categorized under multivariate data analysis. \r\n",
    "    It is similar to a bivariate but contains more than one dependent variable.\r\n",
    "    Example: data for house price prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. How to perform univariate analysis for numerical and categorical variables?\r\n",
    "\r\n",
    "    For the Numerical variables:\r\n",
    "    One can plot a Box and Whiskers plot and KDE plot to better understand the data; below is an example of the Age column plotted using both box and KDE plot. \r\n",
    "\r\n",
    "    For the Categorical variables:\r\n",
    "    Bar plots and Pie Charts are a great way to analyze categorical variables to understand the categorical data. The two plots represent the number (in a bar chart) and proportion (in a pie chart) of individuals opting for Course_types."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. What is regularization and what are the different types of regularization methods available.\r\n",
    "Overfitting is a phenomenon that occurs when a Machine Learning model is constraint to training set and not able to perform well on unseen data. \r\n",
    "\r\n",
    "Regularization is a technique used to reduce the errors by fitting the function appropriately on the given training set and avoid overfitting. \r\n",
    "The commonly used regularization techniques are : \r\n",
    "    L1 regularization\r\n",
    "    L2 regularization\r\n",
    "    Dropout regularization\r\n",
    "\r\n",
    "A regression model which uses L1 Regularization technique is called LASSO(Least Absolute Shrinkage and Selection Operator) regression.  - Lasso Regression adds “absolute value of magnitude” of coefficient as penalty term to the loss function(L). \r\n",
    "A regression model that uses L2 regularization technique is called Ridge regression. - Ridge regression adds “squared magnitude” of coefficient as penalty term to the loss function(L). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Hyperparameter Tuning\r\n",
    "Hyperparameter types:\r\n",
    "\r\n",
    "    K in K-NN\r\n",
    "    Regularization constant, kernel type, and constants in SVMs\r\n",
    "    Number of layers, number of units per layer, regularization in neural network\r\n",
    "\r\n",
    "Generalization (test) error of learning algorithms has two main components:\r\n",
    "\r\n",
    "    Bias: error due to simplifying model assumptions\r\n",
    "    Variance: error due to randomness of the training set\r\n",
    "\r\n",
    "The trade-off between these components is determined by the complexity of the model and the amount of training data. The optimal hyperparameters help to avoid under-fitting (training and test error are both high) and over-fitting (Training error is low but test error is high)\r\n",
    "\r\n",
    "Hyperparameter Tuning\r\n",
    "\r\n",
    "Hyperparameters: Vanilla linear regression does not have any hyperparameters. Variants of linear regression (ridge and lasso) have regularization as a hyperparameter. The decision tree has max depth and min number of observations in leaf as hyperparameters.\r\n",
    "\r\n",
    "Optimal Hyperparameters: Hyperparameters control the over-fitting and under-fitting of the model. Optimal hyperparameters often differ for different datasets. To get the best hyperparameters the following steps are followed:\r\n",
    "\r\n",
    "1. For each proposed hyperparameter setting the model is evaluated\r\n",
    "\r\n",
    "2. The hyperparameters that give the best model are selected.\r\n",
    "\r\n",
    "Hyperparameters Search: Grid search picks out a grid of hyperparameter values and evaluates all of them. Guesswork is necessary to specify the min and max values for each hyperparameter. Random search randomly values a random sample of points on the grid. It is more efficient than grid search. Smart hyperparameter tuning picks a few hyperparameter settings, evaluates the validation matrices, adjusts the hyperparameters, and re-evaluates the validation matrices. Examples of smart hyper-parameter are Spearmint (hyperparameter optimization using Gaussian processes) and Hyperopt (hyperparameter optimization using Tree-based estimators)."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}